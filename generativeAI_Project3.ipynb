{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qY1lXPCAJg2E"
   },
   "source": [
    "# PEFT tutorial using Hugging Face\n",
    "## 教學目標\n",
    "利用 Hugging Face 套件快速使用 PEFT 來進行下游任務訓練\n",
    "- 單一句型分類任務 (single-sentence text classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNg9uH2-Jg2H"
   },
   "source": [
    "## 適用對象\n",
    "已經有基本的機器學習知識，且擁有 Python、`numpy`、`pandas`、`scikit-learn` 以及 `PyTorch` 基礎的學生。\n",
    "\n",
    "若沒有先學過 Python，請參考 [python-入門語法](./python-入門語法.ipynb) 教學。\n",
    "\n",
    "若沒有先學過 `pandas`，請參考 [pandas-基本功能](./pandas-基本功能.ipynb) 教學。\n",
    "\n",
    "若沒有先學過 `numpy`，請參考 [numpy-基本功能](./numpy-基本功能.ipynb) 教學。\n",
    "\n",
    "若沒有先學過 `scikit-learn`，請參考 [scikit-learn-基本功能](./scikit-learn-基本功能.ipynb) 教學。\n",
    "\n",
    "若沒有先學過  `PyTorch` ，請參考 [PyTorch-基本功能](./PyTorch-基本功能.ipynb) 教學。\n",
    "\n",
    "若沒有先學過如何使用 `PyTorch` 建立自然語言處理序列模型，請參考 [NN-中文文本分類](./NN-中文文本分類.ipynb) 教學。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PEFT 簡易介紹\n",
    "### 對大語言模型進行微調的挑戰\n",
    "- 大語言模型的通常是以大量的文本資料進行訓練，並且在多個任務上取得了驚人的表現。\n",
    "- 若我們想要將這些大語言模型應用在自己的任務上，通常需要進行微調。\n",
    "- 但是對於大語言模型進行微調是一個挑戰，因為這些模型通常有數十億甚至數百億的參數，並且需要大量的計算資源。\n",
    "- 這就是為什麼我們需要 PEFT 這個套件，它可以幫助我們快速的進行大語言模型的微調。\n",
    "![](https://i.imgur.com/q6u4GVJ.png)\n",
    "- 更多細節請參考 ([Peft github](https://github.com/huggingface/peft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7n0nQj0qJg2I"
   },
   "source": [
    "## PEFT 範例: LoRA\n",
    "![](https://i.imgur.com/GCsNYXF.png)\n",
    "- 請參考理論層面的詳細教學 ([影片連結](https://www.youtube.com/watch?v=dA-NhCtrrVE))\n",
    "- 也可以參考原始論文 ([論文連結](https://arxiv.org/abs/2106.09685))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OT5oltZrJg2J"
   },
   "source": [
    "## Hugging Face 介紹\n",
    "- 🤗 Hugging Face 是專門提供自然語言處理領域的函式庫\n",
    "- 其函式庫支援 PyTorch 和 TensorFlow\n",
    "- 🤗 Hugging Face 的主要套件為:\n",
    "    1. Transformers ([連結](https://huggingface.co/transformers/index.html))\n",
    "    - 提供了現今最強大的自然語言處理模型，使用上非常彈性且方便\n",
    "    2. Tokenizers ([連結](https://huggingface.co/docs/tokenizers/python/latest/))\n",
    "    - 讓你可以快速做好 BERT 系列模型 tokenization\n",
    "    3. Datasets ([連結](https://huggingface.co/docs/datasets/))\n",
    "    - 提供多種自然語言處理任務的資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TUjyDQ-qJg2J",
    "outputId": "90b838b2-f0bb-4c14-fc20-1e92324695b2"
   },
   "outputs": [],
   "source": [
    "# 若沒有安裝 transformers 和 datasets 套件，請取消以下註解並執行\n",
    "# !pip install transformers==4.38.0\n",
    "# !pip install datasets\n",
    "# !pip install torch==2.0.1+cu110\n",
    "# !pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/NVIDIA/apex\n",
    "# %cd apex\n",
    "# !pip install -r requirements.txt\n",
    "# !pip install -v --disable-pip-version-check --no-cache-dir ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z3tiYaLoJg2K",
    "outputId": "f9bb0cf9-8aec-404a-9c29-2074542caeb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 的版本為: 2.1.2+cu118\n",
      "Hugging Face Transformers 的版本為: 4.39.3\n",
      "Hugging Face Datasets 的版本為: 2.18.0\n",
      "PEFT 的版本為: 0.10.0\n"
     ]
    }
   ],
   "source": [
    "# 確認所需套件的版本\n",
    "import torch\n",
    "print(\"PyTorch 的版本為: {}\".format(torch.__version__))\n",
    "\n",
    "import transformers\n",
    "print(\"Hugging Face Transformers 的版本為: {}\".format(transformers.__version__))\n",
    "\n",
    "import datasets\n",
    "print(\"Hugging Face Datasets 的版本為: {}\".format(datasets.__version__))\n",
    "\n",
    "import peft\n",
    "print(\"PEFT 的版本為: {}\".format(peft.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "s-JMEX4oJg2L"
   },
   "outputs": [],
   "source": [
    "# 載入其他所需套件\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path # (Python3.4+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: 資料載入\n",
    "本次作業要求選擇GLUE benchmark中的資料集至少兩個\\\n",
    "以上是一種讀取資料集的範例，但具體怎麼讀不做要求，可以直接用huggingface的load_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dW2UFRcGJg2N"
   },
   "source": [
    "## Hugging Face AutoTokenizer\n",
    "- 使用 AutoTokenizer 搭配 Hugging Face models 的名稱可以直接呼叫使用\n",
    "- 舉例:\n",
    "    - transformers.AutoTokenizer.from_pretrained('roberta-base')\n",
    "- [點這裡來查看 Hugging Face models 的名稱](https://huggingface.co/transformers/pretrained_models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "smRMfe1RJg2N",
    "outputId": "216957f3-89c2-45cd-f463-560ddf7c20ce"
   },
   "outputs": [],
   "source": [
    "# 載入 tokenizer\n",
    "\n",
    "# 在 Hugging Face 套件中可使用 .from_pretrained() 的方法來導入預訓練模型\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('roberta-base', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlHobatFJg2O"
   },
   "source": [
    "## Hugging Face Datasets\n",
    "- Hugging Face Datasets 已經幫你收錄了自然語言處理領域常見的資料集\n",
    "- 直接呼叫 Datasets 並搭配下面幾個 cells 的語法，可省下不少時間\n",
    "- 但前提是你要進行的任務資料集有被收錄在 Hugging Face Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLUE benchmark - CoLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "o5nX6CEYJg2O"
   },
   "outputs": [],
   "source": [
    "# 從 Hugging Face Datasets 載入資料並做資料切分\n",
    "\n",
    "# 載入 CoLA 的訓練資料集\n",
    "train_cola = datasets.load_dataset(\"glue\", \"cola\", split=\"train\", cache_dir=\"./cache/cola/train\")\n",
    "\n",
    "# 載入 CoLA 的驗證資料集\n",
    "valid_cola = datasets.load_dataset(\"glue\", \"cola\", split=\"validation\", cache_dir=\"./cache/cola/valid\")\n",
    "\n",
    "# 載入 CoLA 的測試資料集\n",
    "test_cola = datasets.load_dataset(\"glue\", \"cola\", split=\"test\", cache_dir=\"./cache/cola/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TU4Zkxx2Jg2O",
    "outputId": "48fe75f5-70f8-4eb1-8765-a245d39de219"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8551 1043 1063\n"
     ]
    }
   ],
   "source": [
    "print(len(train_cola), len(valid_cola), len(test_cola))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['unacceptable', 'acceptable'], id=None),\n",
       " 'idx': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cola.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDGsIlStJg2O",
    "outputId": "80f30607-bf84-4b7e-a03c-f9b932d1cec3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看 max_length\n",
    "\n",
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "08040ed6406841cdb419bc520c27b0aa",
      "d92e9c53c0cc4b38afefb821b615b01c",
      "08319e9ed1b9480baae1a5d697b8cc10",
      "b86ee9c64f494d7bbefab8b86bc84da3",
      "3938d967b7414535ba6b5011dc56470f",
      "1dfed01ed6bf4f04994cf26f439380f7",
      "23697ab45e464e31bbf0f7e3883dce11",
      "bcdeab999f3b48a9aae8c12420b2bfcb",
      "daaf705153f7406682246dfe5d7321f7",
      "409db3f8a55a4cd28696e66074773aab",
      "f36b9796a29f45d980986087aeb79d42",
      "3a5a32b8db02492abf45cc1a5c111d7c",
      "608e362d2f92485a97e3556fd370957b",
      "ec632d4d34544dd989df07c1c26f2467",
      "00dee68c6ffd43a4b5cf30f09d71bcb0",
      "0ea9133bf4664aee8c6dd74eda254cc5",
      "fae4e545f58e4ca9aa1f49bad91a36d4",
      "fece13fdff59433ebbb3a35320574e5f",
      "87a9ce7ed8fa43988c59bb3d9ced637b",
      "4938681ec83a4338a20288242b762122",
      "f06d935a23144d0eba94969c6ea91cbb",
      "8e95a576f3d34366beb19b5bde93dc5b",
      "b9548eee1f3c45f3b49865e4a625d00f",
      "3299d0d455874ab38b7f3545d9c73e79",
      "7a142a6dd37b46daa64feff35f4168c6",
      "f5de6cf424a54676bb153afa6cfe96a4",
      "1ec526cda13940a6b77fdd623b69f1f7",
      "339e040e2baf4dcf900b6d76abeb2c14",
      "02168fc723b143849b7d8488d4b73997",
      "1fe8a068cd744e8ca846095190e977dc",
      "6df9c93e3e6e4f94b48b1f2df6b350c3",
      "a0bb14037015498794f441bcbac020da",
      "620d401375d7406e8922d7c51246bd31"
     ]
    },
    "id": "mOT5JmqFJg2O",
    "outputId": "6b1b8a2b-6592-4604-b99b-79d6b1ab5451"
   },
   "outputs": [],
   "source": [
    "# 將 Hugging Face Datasets 轉為 PyTorch Dataset 的封裝\n",
    "\n",
    "def cola_to_torch_data(hug_dataset):\n",
    "    \"\"\"將 Hugging Face Datasets 轉為 PyTorch Dataset\n",
    "    Args:\n",
    "        - hug_dataset: 從 Datasets 載入的資料集\n",
    "    Return:\n",
    "        - dataset: 已轉為 PyTorch Dataset 的資料集\n",
    "    \"\"\"\n",
    "    dataset = hug_dataset.map(\n",
    "        lambda batch: tokenizer(\n",
    "            batch[\"sentence\"],\n",
    "            truncation=True,\n",
    "            padding=True\n",
    "        ),\n",
    "        batched=True\n",
    "    )\n",
    "    dataset.set_format(\n",
    "        type='torch',\n",
    "        columns=[\n",
    "            'input_ids',\n",
    "            'attention_mask',\n",
    "            'label'\n",
    "        ]\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "train_dataset_cola = cola_to_torch_data(train_cola)\n",
    "val_dataset_cola = cola_to_torch_data(valid_cola)\n",
    "test_dataset_cola = cola_to_torch_data(test_cola)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLUE Benchmark - MRPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 從 Hugging Face Datasets 載入資料並做資料切分\n",
    "\n",
    "# 載入 MRPC 的訓練資料集\n",
    "train_mrpc = datasets.load_dataset(\"glue\", \"mrpc\", split=\"train\", cache_dir=\"./cache/mrpc/train\")\n",
    "\n",
    "# 載入 MRPC 的驗證資料集\n",
    "valid_mrpc = datasets.load_dataset(\"glue\", \"mrpc\", split=\"validation\", cache_dir=\"./cache/mrpc/valid\")\n",
    "\n",
    "# 載入 MRPC 的測試資料集\n",
    "test_mrpc = datasets.load_dataset(\"glue\", \"mrpc\", split=\"test\", cache_dir=\"./cache/mrpc/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TU4Zkxx2Jg2O",
    "outputId": "48fe75f5-70f8-4eb1-8765-a245d39de219"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3668 408 1725\n"
     ]
    }
   ],
   "source": [
    "print(len(train_mrpc), len(valid_mrpc), len(test_mrpc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': Value(dtype='string', id=None),\n",
       " 'sentence2': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\n",
       " 'idx': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mrpc.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 Hugging Face Datasets 轉為 PyTorch Dataset 的封裝\n",
    "\n",
    "def mrpc_to_torch_data(hug_dataset):\n",
    "    \"\"\"將 Hugging Face Datasets 轉為 PyTorch Dataset\n",
    "    Args:\n",
    "        - hug_dataset: 從 Datasets 載入的資料集\n",
    "    Return:\n",
    "        - dataset: 已轉為 PyTorch Dataset 的資料集\n",
    "    \"\"\"\n",
    "    dataset = hug_dataset.map(\n",
    "        lambda batch: tokenizer(\n",
    "            batch[\"sentence1\"],\n",
    "            batch[\"sentence2\"],\n",
    "            truncation=True,\n",
    "            padding=True\n",
    "        ),\n",
    "        batched=True\n",
    "    )\n",
    "    dataset.set_format(\n",
    "        type='torch',\n",
    "        columns=[\n",
    "            'input_ids',\n",
    "            'attention_mask',\n",
    "            'label'\n",
    "        ]\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "train_dataset_mrpc = mrpc_to_torch_data(train_mrpc)\n",
    "val_dataset_mrpc = mrpc_to_torch_data(valid_mrpc)\n",
    "test_dataset_mrpc = mrpc_to_torch_data(test_mrpc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfGCHkFpJg2O"
   },
   "source": [
    "## 檢查 tokenization 後的結果\n",
    "- 使用 Hugging Face tokenizer 進行 tokenization 後的結果是一個 dict\n",
    "- 這個 dict 的 keys 包含 'input_ids' 和 'attention_mask'\n",
    "- input_ids: 原本句子中的每個字詞被斷詞後轉換成字典的 ID\n",
    "    - 注意!! tokenizer 小小的動作已經幫你完成了斷詞和 word to ID 的轉換\n",
    "- attention_mask: tokenization 後句子中包含文字的部分為 1，padding 的部分為 0\n",
    "    - 可以想像成模型需要把注意力放在有文字的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(1),\n",
       " 'input_ids': tensor([    0,  3762,    55, 38283,   937,  1938,     8,    38,   437,  1311,\n",
       "            62,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_cola[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(0),\n",
       " 'input_ids': tensor([    0,   975, 26802,  1588,   102,  2164, 13976,  1758,   128,    29,\n",
       "           137,  2183,     5,  3206,     7, 11881, 10564,    11,  6708,    13,\n",
       "            68,   132,     4,   245,   325,   479,     2,     2,   975, 26802,\n",
       "          1588,   102,  2162, 13976,  1758,   128,    29,    11,  7969,    13,\n",
       "            68,   231,  6478,   153,     8,  1088,    24,     7, 11881, 10564,\n",
       "            13,    68,   112,     4,   398,   325,    11,  6708,   479,     2,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_mrpc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MF4ZQrNJg2O"
   },
   "source": [
    "## 使用 Hugging Face 的模型\n",
    "- 在這個 API 盛行的世代，總是有人幫你設想周到\n",
    "- [Hugging Face 的模型頁面連結](https://huggingface.co/models)\n",
    "- 以 Roberta 為例，只要透過 AutoModel.from_pretrained(\"roberta-base\")，就可以直接使用 RobertaModel\n",
    "- 需要注意的是接下來你要做怎樣的下游任務訓練\n",
    "- 同樣以 Roberta 為例，在原始論文中 Roberta 進行過以下的任務:\n",
    "    - Sentence pair classification: MNLI/QQP/QNLI/MRPC/RTE/WNLI\n",
    "        - 對應 `RobertaForSequenceClassification`\n",
    "        - 使用雙句結合，並以分類的方式進行訓練\n",
    "    - Semantic textual similarity: STS-B\n",
    "        - `RobertaForSequenceClassification`\n",
    "        - 使用雙句結合，並以迴歸的方式進行訓練\n",
    "    - Single sentence classification: SST-2/CoLA\n",
    "        - 對應 `RobertaForSequenceClassification`\n",
    "        - 使用單句，並以迴歸的方式進行訓練\n",
    "    - Question answering: SQuAD v1.1/v2.0\n",
    "        - 對應 `RobertaForQuestionAnswering`\n",
    "        - 使用雙句(問題+原文)，並透過答案在原文中的位置進行訓練\n",
    "    - Named-entity recognition (slot filling): CoNLL-2003\n",
    "        - 對應 `RobertaForTokenClassification`\n",
    "        - 使用單句，並以分類的方式進行訓練\n",
    "- 如果要進行的下游任務訓練不在 Hugging Face 已經建好的模型範圍，那就需要自己寫一個 model class:\n",
    "    1. 繼承 torch.nn.Module\n",
    "    2. 利用 super 來繼承所有親屬類別的實體屬性\n",
    "    3. 定義欲使用的 pre-trained model\n",
    "    4. 定義會使用到的層如 linear 或 Dropout 等\n",
    "    5. 設計 forward function 並且設定下游任務的輸出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sFWgVD0Jg2P"
   },
   "source": [
    "## 進行模型的訓練\n",
    "### 使用 Hugging Face Trainer ([Documentation](https://huggingface.co/transformers/main_classes/trainer.html))\n",
    "- Trainer 是 Hugging Face 中高度封裝的套件之一，負責模型訓練時期的\"流程\"\n",
    "- 過去我們自行寫訓練流程的程式碼可以交給 Trainer\n",
    "- Trainer 需要搭配使用 [TrainingArguments](https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments)\n",
    "    - TrainingArguments 是 Trainer 所需要的引數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task2: 模型驗證\n",
    "這裏要求同學們撰寫computer_metrics函式 \\\n",
    "要求同學們參考GLUE benchmark的官方網頁，使用和資料集對應的evaluation matrics\\\n",
    "回傳一個測試結果的dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KZgSNytdJg2P"
   },
   "outputs": [],
   "source": [
    "# 建立自定的評估的指標 (定義 function)\n",
    "# 將作為 transformers.Trainer 的 parameters 之一\n",
    "\n",
    "# Scikit-learn 的 precision_recall_fscore_support 套件可以一次計算 F1 score, precision, 和 recall\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from datasets import load_metric\n",
    "\n",
    "def compute_metrics_cola(eval_preds):\n",
    "    # 請參考GLUE benchmark的官方網頁，使用和資料集對應的evaluation matrics\n",
    "    metric = datasets.load_metric(\"glue\", \"cola\")\n",
    "    logits, labels = eval_preds.predictions, eval_preds.label_ids\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "def compute_metrics_mrpc(eval_preds):\n",
    "    # 請參考GLUE benchmark的官方網頁，使用和資料集對應的evaluation matrics\n",
    "    metric = datasets.load_metric(\"glue\", \"mrpc\")\n",
    "    logits, labels = eval_preds.predictions, eval_preds.label_ids\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = transformers.DataCollatorWithPadding(\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task3: PEFT \n",
    "在這個模塊中，我們要求同學們把模型改成PEFT的形式（Bitfit、LoRA或者其他）\\\n",
    "同學們可以將模型的可訓練參數量print出來\n",
    "\n",
    "以下是各個資料集的baseline: \n",
    "\n",
    "|dataset|metrics|baseline|\n",
    "|----|----|----|\n",
    "|CoLA|Matthew's Corr|0.6|\n",
    "|SST2|Accuracy|0.88|\n",
    "|MRPC|Accuracy|0.8|\n",
    "|STSB|Pearson-Spearman Corr|0.8|\n",
    "|QQP|F1 / Accuracy|0.8/0.8|\n",
    "|MNLI_Matched|Accuracy|0.8|\n",
    "|MNLI_Mismatched|Accuracy|0.8|\n",
    "|QNLI|Accuracy|0.85|\n",
    "|RTE|Accuracy|0.7|\n",
    "|WNLI|Accuracy|0.8|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "wHfKgmDjJg2U",
    "jp-MarkdownHeadingCollapsed": true,
    "outputId": "8a01ba35-e9ea-4db1-aceb-1e71b633022c"
   },
   "source": [
    "#### LoRA on CoLA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,181,954 || all params: 125,829,124 || trainable%: 0.9393326142841144\n"
     ]
    }
   ],
   "source": [
    "# LoRA 訓練設定\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    " \n",
    "# Define LoRA Config\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    inference_mode=False,\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")\n",
    "\n",
    "# add LoRA adaptor\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", trust_remote_code=True)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='340' max='340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [340/340 05:42, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.607600</td>\n",
       "      <td>0.685670</td>\n",
       "      <td>0.301826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.481800</td>\n",
       "      <td>0.496303</td>\n",
       "      <td>0.469179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.423300</td>\n",
       "      <td>0.464689</td>\n",
       "      <td>0.480204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.369700</td>\n",
       "      <td>0.456541</td>\n",
       "      <td>0.565160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.406895</td>\n",
       "      <td>0.585751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.309500</td>\n",
       "      <td>0.414831</td>\n",
       "      <td>0.588414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.271200</td>\n",
       "      <td>0.456625</td>\n",
       "      <td>0.583025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.259400</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.583940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.244200</td>\n",
       "      <td>0.494482</td>\n",
       "      <td>0.583025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.233700</td>\n",
       "      <td>0.505460</td>\n",
       "      <td>0.590523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22754/2882079743.py:10: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"glue\", \"cola\")\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=340, training_loss=0.35362693001242246, metrics={'train_runtime': 344.7826, 'train_samples_per_second': 248.011, 'train_steps_per_second': 0.986, 'total_flos': 2093805016160880.0, 'train_loss': 0.35362693001242246, 'epoch': 10.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練模型\n",
    "\n",
    "# 設定 TrainingArguments\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"LoRA_CoLA\",        # 輸出的資料夾\n",
    "    num_train_epochs=10,              # 總共訓練的 epoch 數目\n",
    "    learning_rate=1e-3,              # 學習率\n",
    "    per_device_train_batch_size=256,  # 訓練模型時每個裝置的 batch size\n",
    "    per_device_eval_batch_size=256,   # 驗證模型時每個裝置的 batch size\n",
    "    gradient_accumulation_steps=1,   # 梯度累積的步數\n",
    "    warmup_steps=10,                # learning rate scheduler 的參數\n",
    "    weight_decay=1e-4,               # 最佳化演算法 (optimizer) 中的權重衰退率\n",
    "    evaluation_strategy='epoch',     # 設定驗證的時機\n",
    "    save_strategy='epoch',           # 設定儲存的時機\n",
    "    logging_steps=0.1,\n",
    "    seed=100\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,                         # 🤗 的模型\n",
    "    args=training_args,                  # Trainer 所需要的引數\n",
    "    train_dataset=train_dataset_cola,         # 訓練集 (注意是 PyTorch Dataset)\n",
    "    eval_dataset=val_dataset_cola,            # 驗證集 (注意是 PyTorch Dataset)，可使 Trainer 在進行訓練時也進行驗證\n",
    "    compute_metrics=compute_metrics_cola,     # 自定的評估的指標\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# 指定使用 1 個 GPU 進行訓練\n",
    "trainer.args._n_gpu=1\n",
    "\n",
    "# 開始進行模型訓練\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "wHfKgmDjJg2U",
    "jp-MarkdownHeadingCollapsed": true,
    "outputId": "8a01ba35-e9ea-4db1-aceb-1e71b633022c"
   },
   "source": [
    "#### LoRA on MRPC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,181,954 || all params: 125,829,124 || trainable%: 0.9393326142841144\n"
     ]
    }
   ],
   "source": [
    "# LoRA 訓練設定\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    " \n",
    "# Define LoRA Config\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    inference_mode=False,\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")\n",
    "\n",
    "# add LoRA adaptor\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", trust_remote_code=True)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='290' max='290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [290/290 05:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.640400</td>\n",
       "      <td>0.636725</td>\n",
       "      <td>0.713235</td>\n",
       "      <td>0.825112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.503800</td>\n",
       "      <td>0.347224</td>\n",
       "      <td>0.845588</td>\n",
       "      <td>0.886894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.399300</td>\n",
       "      <td>0.333836</td>\n",
       "      <td>0.845588</td>\n",
       "      <td>0.889667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.317500</td>\n",
       "      <td>0.347127</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.916376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.264200</td>\n",
       "      <td>0.302864</td>\n",
       "      <td>0.865196</td>\n",
       "      <td>0.901257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.225700</td>\n",
       "      <td>0.396562</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.903010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.201500</td>\n",
       "      <td>0.346742</td>\n",
       "      <td>0.879902</td>\n",
       "      <td>0.915078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.170400</td>\n",
       "      <td>0.398173</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.906897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.144100</td>\n",
       "      <td>0.396105</td>\n",
       "      <td>0.877451</td>\n",
       "      <td>0.911972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.130100</td>\n",
       "      <td>0.404473</td>\n",
       "      <td>0.877451</td>\n",
       "      <td>0.912281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2985/2882079743.py:17: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"glue\", \"mrpc\")\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=290, training_loss=0.2997131816272078, metrics={'train_runtime': 342.8572, 'train_samples_per_second': 106.983, 'train_steps_per_second': 0.846, 'total_flos': 1987394748218880.0, 'train_loss': 0.2997131816272078, 'epoch': 10.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練模型\n",
    "\n",
    "# 設定 TrainingArguments\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"LoRA_MRPC\",        # 輸出的資料夾\n",
    "    num_train_epochs=10,              # 總共訓練的 epoch 數目\n",
    "    learning_rate=1e-3,              # 學習率\n",
    "    per_device_train_batch_size=128,  # 訓練模型時每個裝置的 batch size\n",
    "    per_device_eval_batch_size=128,   # 驗證模型時每個裝置的 batch size\n",
    "    gradient_accumulation_steps=1,   # 梯度累積的步數\n",
    "    warmup_steps=10,                # learning rate scheduler 的參數\n",
    "    weight_decay=1e-4,               # 最佳化演算法 (optimizer) 中的權重衰退率\n",
    "    evaluation_strategy='epoch',     # 設定驗證的時機\n",
    "    save_strategy='epoch',           # 設定儲存的時機\n",
    "    logging_steps=0.1,\n",
    "    seed=100\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,                         # 🤗 的模型\n",
    "    args=training_args,                  # Trainer 所需要的引數\n",
    "    train_dataset=train_dataset_mrpc,         # 訓練集 (注意是 PyTorch Dataset)\n",
    "    eval_dataset=val_dataset_mrpc,            # 驗證集 (注意是 PyTorch Dataset)，可使 Trainer 在進行訓練時也進行驗證\n",
    "    compute_metrics=compute_metrics_mrpc,     # 自定的評估的指標\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# 指定使用 1 個 GPU 進行訓練\n",
    "trainer.args._n_gpu=1\n",
    "\n",
    "# 開始進行模型訓練\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "wHfKgmDjJg2U",
    "jp-MarkdownHeadingCollapsed": true,
    "outputId": "8a01ba35-e9ea-4db1-aceb-1e71b633022c"
   },
   "source": [
    "#### BitFit on CoLA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 102914 || all params: 124647170 || trainable%: 0.08256424915222704\n"
     ]
    }
   ],
   "source": [
    "# BitFit 訓練設定\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", trust_remote_code=True)\n",
    "\n",
    "trainable_params = 0\n",
    "all_param = 0\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    all_param += param.numel()\n",
    "    if \"bias\" not in name:\n",
    "        param.require_grad = False\n",
    "    else:\n",
    "        param.require_grad = True\n",
    "        trainable_params += param.numel()\n",
    "\n",
    "print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1340' max='1340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1340/1340 09:41, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.539100</td>\n",
       "      <td>0.418387</td>\n",
       "      <td>0.548265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.439593</td>\n",
       "      <td>0.526136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.259200</td>\n",
       "      <td>0.574695</td>\n",
       "      <td>0.553641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.174300</td>\n",
       "      <td>0.589701</td>\n",
       "      <td>0.600984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.645020</td>\n",
       "      <td>0.590990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.677215</td>\n",
       "      <td>0.599641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.906343</td>\n",
       "      <td>0.562623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>0.816503</td>\n",
       "      <td>0.603317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.945155</td>\n",
       "      <td>0.608684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>1.074773</td>\n",
       "      <td>0.595616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1340, training_loss=0.1744336220755506, metrics={'train_runtime': 582.1451, 'train_samples_per_second': 146.888, 'train_steps_per_second': 2.302, 'total_flos': 2064580034754360.0, 'train_loss': 0.1744336220755506, 'epoch': 10.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練模型\n",
    "\n",
    "# 設定 TrainingArguments\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"BitFit_CoLA\",        # 輸出的資料夾\n",
    "    num_train_epochs=10,              # 總共訓練的 epoch 數目\n",
    "    learning_rate=1e-4,              # 學習率\n",
    "    per_device_train_batch_size=64,  # 訓練模型時每個裝置的 batch size\n",
    "    per_device_eval_batch_size=64,   # 驗證模型時每個裝置的 batch size\n",
    "    gradient_accumulation_steps=1,   # 梯度累積的步數\n",
    "    warmup_steps=10,                # learning rate scheduler 的參數\n",
    "    weight_decay=1e-5,               # 最佳化演算法 (optimizer) 中的權重衰退率\n",
    "    evaluation_strategy='epoch',     # 設定驗證的時機\n",
    "    save_strategy='epoch',           # 設定儲存的時機\n",
    "    logging_steps=0.1,\n",
    "    seed=100\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,                         # 🤗 的模型\n",
    "    args=training_args,                  # Trainer 所需要的引數\n",
    "    train_dataset=train_dataset_cola,         # 訓練集 (注意是 PyTorch Dataset)\n",
    "    eval_dataset=val_dataset_cola,            # 驗證集 (注意是 PyTorch Dataset)，可使 Trainer 在進行訓練時也進行驗證\n",
    "    compute_metrics=compute_metrics_cola,     # 自定的評估的指標\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# 指定使用 1 個 GPU 進行訓練\n",
    "trainer.args._n_gpu=1\n",
    "\n",
    "# 開始進行模型訓練\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "wHfKgmDjJg2U",
    "jp-MarkdownHeadingCollapsed": true,
    "outputId": "8a01ba35-e9ea-4db1-aceb-1e71b633022c"
   },
   "source": [
    "#### BitFit on MRPC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 102914 || all params: 124647170 || trainable%: 0.08256424915222704\n"
     ]
    }
   ],
   "source": [
    "# BitFit 訓練設定\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", trust_remote_code=True)\n",
    "\n",
    "trainable_params = 0\n",
    "all_param = 0\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    all_param += param.numel()\n",
    "    if \"bias\" not in name:\n",
    "        param.require_grad = False\n",
    "    else:\n",
    "        param.require_grad = True\n",
    "        trainable_params += param.numel()\n",
    "\n",
    "print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='580' max='580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [580/580 08:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.600100</td>\n",
       "      <td>0.451975</td>\n",
       "      <td>0.776961</td>\n",
       "      <td>0.856693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.434700</td>\n",
       "      <td>0.356418</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.884477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.344600</td>\n",
       "      <td>0.376615</td>\n",
       "      <td>0.828431</td>\n",
       "      <td>0.866412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.225400</td>\n",
       "      <td>0.309359</td>\n",
       "      <td>0.870098</td>\n",
       "      <td>0.903108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.140400</td>\n",
       "      <td>0.359604</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.904594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.087100</td>\n",
       "      <td>0.509200</td>\n",
       "      <td>0.872549</td>\n",
       "      <td>0.907801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>0.478919</td>\n",
       "      <td>0.879902</td>\n",
       "      <td>0.913580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.676003</td>\n",
       "      <td>0.865196</td>\n",
       "      <td>0.901961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.684587</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.915194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.715340</td>\n",
       "      <td>0.879902</td>\n",
       "      <td>0.912343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=580, training_loss=0.1962397330793841, metrics={'train_runtime': 500.8034, 'train_samples_per_second': 73.242, 'train_steps_per_second': 1.158, 'total_flos': 1960341806841600.0, 'train_loss': 0.1962397330793841, 'epoch': 10.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練模型\n",
    "\n",
    "# 設定 TrainingArguments\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"BitFit_MRPC\",        # 輸出的資料夾\n",
    "    num_train_epochs=10,              # 總共訓練的 epoch 數目\n",
    "    learning_rate=1e-4,              # 學習率\n",
    "    per_device_train_batch_size=64,  # 訓練模型時每個裝置的 batch size\n",
    "    per_device_eval_batch_size=64,   # 驗證模型時每個裝置的 batch size\n",
    "    gradient_accumulation_steps=1,   # 梯度累積的步數\n",
    "    warmup_steps=10,                # learning rate scheduler 的參數\n",
    "    weight_decay=1e-5,               # 最佳化演算法 (optimizer) 中的權重衰退率\n",
    "    evaluation_strategy='epoch',     # 設定驗證的時機\n",
    "    save_strategy='epoch',           # 設定儲存的時機\n",
    "    logging_steps=0.1,\n",
    "    seed=100\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,                         # 🤗 的模型\n",
    "    args=training_args,                  # Trainer 所需要的引數\n",
    "    train_dataset=train_dataset_mrpc,         # 訓練集 (注意是 PyTorch Dataset)\n",
    "    eval_dataset=val_dataset_mrpc,            # 驗證集 (注意是 PyTorch Dataset)，可使 Trainer 在進行訓練時也進行驗證\n",
    "    compute_metrics=compute_metrics_mrpc,     # 自定的評估的指標\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# 指定使用 1 個 GPU 進行訓練\n",
    "trainer.args._n_gpu=1\n",
    "\n",
    "# 開始進行模型訓練\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 比較不同hyper-parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "都是LoRa on CoLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Batch size = 128\n",
    "原本: 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,181,954 || all params: 125,829,124 || trainable%: 0.9393326142841144\n"
     ]
    }
   ],
   "source": [
    "# LoRA 訓練設定\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    " \n",
    "# Define LoRA Config\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    inference_mode=False,\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")\n",
    "\n",
    "# add LoRA adaptor\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", trust_remote_code=True)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='670' max='670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [670/670 06:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.546100</td>\n",
       "      <td>0.508521</td>\n",
       "      <td>0.453590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.415800</td>\n",
       "      <td>0.536687</td>\n",
       "      <td>0.452419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.358500</td>\n",
       "      <td>0.413946</td>\n",
       "      <td>0.575239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.322500</td>\n",
       "      <td>0.406251</td>\n",
       "      <td>0.596038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.273000</td>\n",
       "      <td>0.414675</td>\n",
       "      <td>0.603193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.241000</td>\n",
       "      <td>0.421161</td>\n",
       "      <td>0.604496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>0.535753</td>\n",
       "      <td>0.585706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.191800</td>\n",
       "      <td>0.576062</td>\n",
       "      <td>0.593695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.178900</td>\n",
       "      <td>0.547534</td>\n",
       "      <td>0.603359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.153100</td>\n",
       "      <td>0.607017</td>\n",
       "      <td>0.590675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=670, training_loss=0.29034543677942076, metrics={'train_runtime': 364.2276, 'train_samples_per_second': 234.771, 'train_steps_per_second': 1.84, 'total_flos': 2093805016160880.0, 'train_loss': 0.29034543677942076, 'epoch': 10.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練模型\n",
    "\n",
    "# 設定 TrainingArguments\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"LoRA_CoLA_2\",        # 輸出的資料夾\n",
    "    num_train_epochs=10,              # 總共訓練的 epoch 數目\n",
    "    learning_rate=1e-3,              # 學習率\n",
    "    per_device_train_batch_size=128,  # 訓練模型時每個裝置的 batch size\n",
    "    per_device_eval_batch_size=128,   # 驗證模型時每個裝置的 batch size\n",
    "    gradient_accumulation_steps=1,   # 梯度累積的步數\n",
    "    warmup_steps=10,                # learning rate scheduler 的參數\n",
    "    weight_decay=1e-4,               # 最佳化演算法 (optimizer) 中的權重衰退率\n",
    "    evaluation_strategy='epoch',     # 設定驗證的時機\n",
    "    save_strategy='epoch',           # 設定儲存的時機\n",
    "    logging_steps=0.1,\n",
    "    seed=100\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,                         # 🤗 的模型\n",
    "    args=training_args,                  # Trainer 所需要的引數\n",
    "    train_dataset=train_dataset_cola,         # 訓練集 (注意是 PyTorch Dataset)\n",
    "    eval_dataset=val_dataset_cola,            # 驗證集 (注意是 PyTorch Dataset)，可使 Trainer 在進行訓練時也進行驗證\n",
    "    compute_metrics=compute_metrics_cola,     # 自定的評估的指標\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# 指定使用 1 個 GPU 進行訓練\n",
    "trainer.args._n_gpu=1\n",
    "\n",
    "# 開始進行模型訓練\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Learning Rate = 1e-4\n",
    "原本: 1e-3\n",
    "weight decay 跟著調整, 從 1e-4 -> 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,181,954 || all params: 125,829,124 || trainable%: 0.9393326142841144\n"
     ]
    }
   ],
   "source": [
    "# LoRA 訓練設定\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    " \n",
    "# Define LoRA Config\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    inference_mode=False,\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")\n",
    "\n",
    "# add LoRA adaptor\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", trust_remote_code=True)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='340' max='340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [340/340 05:07, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.482000</td>\n",
       "      <td>0.525661</td>\n",
       "      <td>0.382568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.440600</td>\n",
       "      <td>0.477830</td>\n",
       "      <td>0.458045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.434000</td>\n",
       "      <td>0.525648</td>\n",
       "      <td>0.447911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.421900</td>\n",
       "      <td>0.468637</td>\n",
       "      <td>0.507314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.407900</td>\n",
       "      <td>0.460892</td>\n",
       "      <td>0.510438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.399400</td>\n",
       "      <td>0.437740</td>\n",
       "      <td>0.527461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.391500</td>\n",
       "      <td>0.474434</td>\n",
       "      <td>0.520756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.462667</td>\n",
       "      <td>0.526840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.391200</td>\n",
       "      <td>0.469191</td>\n",
       "      <td>0.528618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.384700</td>\n",
       "      <td>0.452924</td>\n",
       "      <td>0.532110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=340, training_loss=0.4147378388573142, metrics={'train_runtime': 310.0971, 'train_samples_per_second': 275.752, 'train_steps_per_second': 1.096, 'total_flos': 2093805016160880.0, 'train_loss': 0.4147378388573142, 'epoch': 10.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練模型\n",
    "\n",
    "# 設定 TrainingArguments\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"LoRA_CoLA_2\",        # 輸出的資料夾\n",
    "    num_train_epochs=10,              # 總共訓練的 epoch 數目\n",
    "    learning_rate=1e-4,              # 學習率\n",
    "    per_device_train_batch_size=256,  # 訓練模型時每個裝置的 batch size\n",
    "    per_device_eval_batch_size=256,   # 驗證模型時每個裝置的 batch size\n",
    "    gradient_accumulation_steps=1,   # 梯度累積的步數\n",
    "    warmup_steps=10,                # learning rate scheduler 的參數\n",
    "    weight_decay=1e-5,               # 最佳化演算法 (optimizer) 中的權重衰退率\n",
    "    evaluation_strategy='epoch',     # 設定驗證的時機\n",
    "    save_strategy='epoch',           # 設定儲存的時機\n",
    "    logging_steps=0.1,\n",
    "    seed=100\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,                         # 🤗 的模型\n",
    "    args=training_args,                  # Trainer 所需要的引數\n",
    "    train_dataset=train_dataset_cola,         # 訓練集 (注意是 PyTorch Dataset)\n",
    "    eval_dataset=val_dataset_cola,            # 驗證集 (注意是 PyTorch Dataset)，可使 Trainer 在進行訓練時也進行驗證\n",
    "    compute_metrics=compute_metrics_cola,     # 自定的評估的指標\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# 指定使用 1 個 GPU 進行訓練\n",
    "trainer.args._n_gpu=1\n",
    "\n",
    "# 開始進行模型訓練\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 調整LoRA rank(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "wHfKgmDjJg2U",
    "jp-MarkdownHeadingCollapsed": true,
    "outputId": "8a01ba35-e9ea-4db1-aceb-1e71b633022c"
   },
   "source": [
    "### r = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 887,042 || all params: 125,534,212 || trainable%: 0.7066137476531099\n"
     ]
    }
   ],
   "source": [
    "# LoRA 訓練設定\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    " \n",
    "# Define LoRA Config\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    inference_mode=False,\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")\n",
    "\n",
    "# add LoRA adaptor\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", trust_remote_code=True)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='340' max='340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [340/340 05:06, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.561400</td>\n",
       "      <td>0.459850</td>\n",
       "      <td>0.529114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.432200</td>\n",
       "      <td>0.498871</td>\n",
       "      <td>0.520951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.389500</td>\n",
       "      <td>0.406159</td>\n",
       "      <td>0.573511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.357000</td>\n",
       "      <td>0.416802</td>\n",
       "      <td>0.593084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.317700</td>\n",
       "      <td>0.470340</td>\n",
       "      <td>0.586123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.296400</td>\n",
       "      <td>0.408497</td>\n",
       "      <td>0.618264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.267500</td>\n",
       "      <td>0.501184</td>\n",
       "      <td>0.615864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.255800</td>\n",
       "      <td>0.436887</td>\n",
       "      <td>0.618897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.246600</td>\n",
       "      <td>0.528743</td>\n",
       "      <td>0.613466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.510608</td>\n",
       "      <td>0.610736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=340, training_loss=0.33557842338786403, metrics={'train_runtime': 307.1694, 'train_samples_per_second': 278.381, 'train_steps_per_second': 1.107, 'total_flos': 2086693561277040.0, 'train_loss': 0.33557842338786403, 'epoch': 10.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練模型\n",
    "\n",
    "# 設定 TrainingArguments\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"LoRA_CoLA\",        # 輸出的資料夾\n",
    "    num_train_epochs=10,              # 總共訓練的 epoch 數目\n",
    "    learning_rate=1e-3,              # 學習率\n",
    "    per_device_train_batch_size=256,  # 訓練模型時每個裝置的 batch size\n",
    "    per_device_eval_batch_size=256,   # 驗證模型時每個裝置的 batch size\n",
    "    gradient_accumulation_steps=1,   # 梯度累積的步數\n",
    "    warmup_steps=10,                # learning rate scheduler 的參數\n",
    "    weight_decay=1e-4,               # 最佳化演算法 (optimizer) 中的權重衰退率\n",
    "    evaluation_strategy='epoch',     # 設定驗證的時機\n",
    "    save_strategy='epoch',           # 設定儲存的時機\n",
    "    logging_steps=0.1,\n",
    "    seed=100\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,                         # 🤗 的模型\n",
    "    args=training_args,                  # Trainer 所需要的引數\n",
    "    train_dataset=train_dataset_cola,         # 訓練集 (注意是 PyTorch Dataset)\n",
    "    eval_dataset=val_dataset_cola,            # 驗證集 (注意是 PyTorch Dataset)，可使 Trainer 在進行訓練時也進行驗證\n",
    "    compute_metrics=compute_metrics_cola,     # 自定的評估的指標\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# 指定使用 1 個 GPU 進行訓練\n",
    "trainer.args._n_gpu=1\n",
    "\n",
    "# 開始進行模型訓練\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "wHfKgmDjJg2U",
    "jp-MarkdownHeadingCollapsed": true,
    "outputId": "8a01ba35-e9ea-4db1-aceb-1e71b633022c"
   },
   "source": [
    "### r = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,771,778 || all params: 126,418,948 || trainable%: 1.4015130073697497\n"
     ]
    }
   ],
   "source": [
    "# LoRA 訓練設定\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    " \n",
    "# Define LoRA Config\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    inference_mode=False,\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")\n",
    "\n",
    "# add LoRA adaptor\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", trust_remote_code=True)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='340' max='340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [340/340 05:08, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.567400</td>\n",
       "      <td>0.577912</td>\n",
       "      <td>0.390709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.429000</td>\n",
       "      <td>0.494683</td>\n",
       "      <td>0.526048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.385200</td>\n",
       "      <td>0.457663</td>\n",
       "      <td>0.545210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.338500</td>\n",
       "      <td>0.458133</td>\n",
       "      <td>0.580628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.303100</td>\n",
       "      <td>0.429213</td>\n",
       "      <td>0.608191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.281300</td>\n",
       "      <td>0.416304</td>\n",
       "      <td>0.591793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.474691</td>\n",
       "      <td>0.593055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.231500</td>\n",
       "      <td>0.482404</td>\n",
       "      <td>0.593382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.214400</td>\n",
       "      <td>0.501416</td>\n",
       "      <td>0.613252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.207800</td>\n",
       "      <td>0.525970</td>\n",
       "      <td>0.605723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/volley114/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=340, training_loss=0.32091039910035973, metrics={'train_runtime': 309.7485, 'train_samples_per_second': 276.063, 'train_steps_per_second': 1.098, 'total_flos': 2108027925928560.0, 'train_loss': 0.32091039910035973, 'epoch': 10.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練模型\n",
    "\n",
    "# 設定 TrainingArguments\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"LoRA_CoLA\",        # 輸出的資料夾\n",
    "    num_train_epochs=10,              # 總共訓練的 epoch 數目\n",
    "    learning_rate=1e-3,              # 學習率\n",
    "    per_device_train_batch_size=256,  # 訓練模型時每個裝置的 batch size\n",
    "    per_device_eval_batch_size=256,   # 驗證模型時每個裝置的 batch size\n",
    "    gradient_accumulation_steps=1,   # 梯度累積的步數\n",
    "    warmup_steps=10,                # learning rate scheduler 的參數\n",
    "    weight_decay=1e-4,               # 最佳化演算法 (optimizer) 中的權重衰退率\n",
    "    evaluation_strategy='epoch',     # 設定驗證的時機\n",
    "    save_strategy='epoch',           # 設定儲存的時機\n",
    "    logging_steps=0.1,\n",
    "    seed=100\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,                         # 🤗 的模型\n",
    "    args=training_args,                  # Trainer 所需要的引數\n",
    "    train_dataset=train_dataset_cola,         # 訓練集 (注意是 PyTorch Dataset)\n",
    "    eval_dataset=val_dataset_cola,            # 驗證集 (注意是 PyTorch Dataset)，可使 Trainer 在進行訓練時也進行驗證\n",
    "    compute_metrics=compute_metrics_cola,     # 自定的評估的指標\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# 指定使用 1 個 GPU 進行訓練\n",
    "trainer.args._n_gpu=1\n",
    "\n",
    "# 開始進行模型訓練\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00dee68c6ffd43a4b5cf30f09d71bcb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f06d935a23144d0eba94969c6ea91cbb",
      "placeholder": "​",
      "style": "IPY_MODEL_8e95a576f3d34366beb19b5bde93dc5b",
      "value": " 5000/5000 [00:07&lt;00:00, 657.65 examples/s]"
     }
    },
    "02168fc723b143849b7d8488d4b73997": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "08040ed6406841cdb419bc520c27b0aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d92e9c53c0cc4b38afefb821b615b01c",
       "IPY_MODEL_08319e9ed1b9480baae1a5d697b8cc10",
       "IPY_MODEL_b86ee9c64f494d7bbefab8b86bc84da3"
      ],
      "layout": "IPY_MODEL_3938d967b7414535ba6b5011dc56470f"
     }
    },
    "08319e9ed1b9480baae1a5d697b8cc10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bcdeab999f3b48a9aae8c12420b2bfcb",
      "max": 20000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_daaf705153f7406682246dfe5d7321f7",
      "value": 20000
     }
    },
    "0ea9133bf4664aee8c6dd74eda254cc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1dfed01ed6bf4f04994cf26f439380f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ec526cda13940a6b77fdd623b69f1f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1fe8a068cd744e8ca846095190e977dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23697ab45e464e31bbf0f7e3883dce11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3299d0d455874ab38b7f3545d9c73e79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_339e040e2baf4dcf900b6d76abeb2c14",
      "placeholder": "​",
      "style": "IPY_MODEL_02168fc723b143849b7d8488d4b73997",
      "value": "Map: 100%"
     }
    },
    "339e040e2baf4dcf900b6d76abeb2c14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3938d967b7414535ba6b5011dc56470f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a5a32b8db02492abf45cc1a5c111d7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_608e362d2f92485a97e3556fd370957b",
       "IPY_MODEL_ec632d4d34544dd989df07c1c26f2467",
       "IPY_MODEL_00dee68c6ffd43a4b5cf30f09d71bcb0"
      ],
      "layout": "IPY_MODEL_0ea9133bf4664aee8c6dd74eda254cc5"
     }
    },
    "409db3f8a55a4cd28696e66074773aab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4938681ec83a4338a20288242b762122": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "608e362d2f92485a97e3556fd370957b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fae4e545f58e4ca9aa1f49bad91a36d4",
      "placeholder": "​",
      "style": "IPY_MODEL_fece13fdff59433ebbb3a35320574e5f",
      "value": "Map: 100%"
     }
    },
    "620d401375d7406e8922d7c51246bd31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6df9c93e3e6e4f94b48b1f2df6b350c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7a142a6dd37b46daa64feff35f4168c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fe8a068cd744e8ca846095190e977dc",
      "max": 25000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6df9c93e3e6e4f94b48b1f2df6b350c3",
      "value": 25000
     }
    },
    "87a9ce7ed8fa43988c59bb3d9ced637b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e95a576f3d34366beb19b5bde93dc5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0bb14037015498794f441bcbac020da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b86ee9c64f494d7bbefab8b86bc84da3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_409db3f8a55a4cd28696e66074773aab",
      "placeholder": "​",
      "style": "IPY_MODEL_f36b9796a29f45d980986087aeb79d42",
      "value": " 20000/20000 [00:23&lt;00:00, 898.68 examples/s]"
     }
    },
    "b9548eee1f3c45f3b49865e4a625d00f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3299d0d455874ab38b7f3545d9c73e79",
       "IPY_MODEL_7a142a6dd37b46daa64feff35f4168c6",
       "IPY_MODEL_f5de6cf424a54676bb153afa6cfe96a4"
      ],
      "layout": "IPY_MODEL_1ec526cda13940a6b77fdd623b69f1f7"
     }
    },
    "bcdeab999f3b48a9aae8c12420b2bfcb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d92e9c53c0cc4b38afefb821b615b01c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1dfed01ed6bf4f04994cf26f439380f7",
      "placeholder": "​",
      "style": "IPY_MODEL_23697ab45e464e31bbf0f7e3883dce11",
      "value": "Map: 100%"
     }
    },
    "daaf705153f7406682246dfe5d7321f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ec632d4d34544dd989df07c1c26f2467": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87a9ce7ed8fa43988c59bb3d9ced637b",
      "max": 5000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4938681ec83a4338a20288242b762122",
      "value": 5000
     }
    },
    "f06d935a23144d0eba94969c6ea91cbb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f36b9796a29f45d980986087aeb79d42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f5de6cf424a54676bb153afa6cfe96a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0bb14037015498794f441bcbac020da",
      "placeholder": "​",
      "style": "IPY_MODEL_620d401375d7406e8922d7c51246bd31",
      "value": " 25000/25000 [00:27&lt;00:00, 846.66 examples/s]"
     }
    },
    "fae4e545f58e4ca9aa1f49bad91a36d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fece13fdff59433ebbb3a35320574e5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
