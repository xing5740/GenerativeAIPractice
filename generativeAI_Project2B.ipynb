{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGHejOlhxgn2"
   },
   "source": [
    "## 安裝套件\n",
    "! pip install transformers\n",
    "\n",
    "! pip install datasets\n",
    "\n",
    "! pip install torcheval\n",
    "\n",
    "! pip install pytorch-ignite\n",
    "\n",
    " - transformers (4.37.0) huggingface讀取模型的套件\n",
    " - datasets (2.16.1) huggingface讀取資料集的套件\n",
    " - torcheval (0.0.7) 各種評價標準"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fmaIzlYkxgn3"
   },
   "outputs": [],
   "source": [
    "import transformers as T\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from ignite.metrics import Rouge\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "device = \"cuda:2\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwfsJbvyxgn3"
   },
   "source": [
    "## 載入模型\n",
    " - 使用huggingface裝載模型的架構、參數和tokenizer\n",
    " - 保存在路徑./cache/中\n",
    " - 用.to(device)把模型裝載入訓練設備(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "978amJhFxgn3"
   },
   "outputs": [],
   "source": [
    "t5_model = T.T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\", cache_dir=\"./cache/\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(21128, 768)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t5_tokenizer = T.T5Tokenizer.from_pretrained(\"google/flan-t5-base\", cache_dir=\"./cache/\") 他看不懂中文QQ\n",
    "tokenizer = T.BertTokenizer.from_pretrained(\"google-bert/bert-base-chinese\", cache_dir=\"./cache/\", skip_special_tokens=True)\n",
    "\n",
    "tokenizer.add_special_tokens({\"pad_token\": '[PAD]',\n",
    "                              \"cls_token\": '[CLS]',\n",
    "                              \"sep_token\": '[SEP]'\n",
    "                             })\n",
    "\n",
    "t5_model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARnj-n9Kxgn3"
   },
   "source": [
    "## 資料處理\n",
    "使用 torch.utils.data 中的 Dataset 和 Dataloader 成批次地讀取和預處理資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "aHXXUKHRxgn3"
   },
   "outputs": [],
   "source": [
    "def get_tensor(sample):\n",
    "    # 將模型的輸入和ground truth打包成Tensor\n",
    "    model_inputs = tokenizer.batch_encode_plus([each[0] for each in sample], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    model_outputs = tokenizer.batch_encode_plus([each[1] for each in sample], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    return model_inputs[\"input_ids\"].to(device), model_outputs[\"input_ids\"].to(device)\n",
    "\n",
    "class LCSTSDataset(Dataset):\n",
    "    def __init__(self, split=\"train\") -> None:\n",
    "        super().__init__()\n",
    "        assert split in [\"train[:20000]\", \"validation[:10000]\", \"test\"]\n",
    "        data_df = load_dataset(\"hugcyp/LCSTS\", split=split, cache_dir=\"./cache/\").to_pandas()\n",
    "        data_df['text'] = data_df['text'].apply(lambda text: \"文本摘要：\" + text)\n",
    "        self.data = data_df[['text', 'summary']].values.tolist()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset example: \n",
      "['文本摘要：新华社受权于18日全文播发修改后的《中华人民共和国立法法》，修改后的立法法分为“总则”“法律”“行政法规”“地方性法规、自治条例和单行条例、规章”“适用与备案审查”“附则”等6章，共计105条。', '修改后的立法法全文公布'] \n",
      "['文本摘要：一辆小轿车，一名女司机，竟造成9死24伤。日前，深圳市交警局对事故进行通报：从目前证据看，事故系司机超速行驶且操作不当导致。目前24名伤员已有6名治愈出院，其余正接受治疗，预计事故赔偿费或超一千万元。', '深圳机场9死24伤续：司机全责赔偿或超千万']\n"
     ]
    }
   ],
   "source": [
    "data_sample = LCSTSDataset(split=\"train[:20000]\").data[:3]\n",
    "\n",
    "print(f\"Dataset example: \\n{data_sample[0]} \\n{data_sample[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kobvz1xgxgn3"
   },
   "source": [
    "## 超參數\n",
    " - 學習率 (learning rate): 1e-5\n",
    " - 訓練輪數 (epochs): 3\n",
    " - 優化器 (optimizer): AdamW\n",
    " - 批次大小 (batch size): 8\n",
    " - 評量指標 (evaluation matrics)Rouge-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "dWTegnXXxgn3"
   },
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "epochs = 3\n",
    "optimizer = AdamW(t5_model.parameters(), lr = 1e-5)\n",
    "\n",
    "train_batch_size = 8\n",
    "validation_batch_size = 8\n",
    "\n",
    "rouge = Rouge(variants=[\"L\", 2], multiref=\"best\")\n",
    "\n",
    "output_max_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCSTS_train = DataLoader(LCSTSDataset(split=\"train[:20000]\"),\n",
    "                         collate_fn=get_tensor,\n",
    "                         batch_size=train_batch_size,\n",
    "                         shuffle=True)\n",
    "\n",
    "LCSTS_validation = DataLoader(LCSTSDataset(split=\"validation[:10000]\"),\n",
    "                              collate_fn=get_tensor,\n",
    "                              batch_size=validation_batch_size,\n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vP0ZFCSvxgn4"
   },
   "source": [
    "## 驗證\n",
    "驗證程式\n",
    " - 將驗證資料輸入模型，用Rouge-2評價輸出的效果\n",
    " - Rouge的使用方法參考 https://pytorch.org/ignite/generated/ignite.metrics.Rouge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "AyaTmD-Hxgn4"
   },
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    pbar = tqdm(LCSTS_validation)\n",
    "    pbar.set_description(f\"Evaluating\")\n",
    "\n",
    "    for inputs, summary in pbar:\n",
    "        output = [tokenizer.batch_decode(model.generate(inputs, max_length=output_max_length))]\n",
    "        summary = [tokenizer.batch_decode(summary)]\n",
    "        for i in range(len(output)):\n",
    "            for s in output:\n",
    "                rouge.update(([s], [summary]))\n",
    "    return rouge.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGZgD2IBxgn4"
   },
   "source": [
    "## T5 訓練 & 測試\n",
    " - 將資料成批次輸入T5模型，並獲取其損失函數數值，隨後計算梯度優化\n",
    " - tqdm用來顯示模型的訓練進度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "MjPwHOCmxgn4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch [1/3]: 100%|███████████████████████████████████████████████████████| 2500/2500 [08:41<00:00,  4.79it/s, loss=3.11]\n",
      "Training epoch [2/3]: 100%|███████████████████████████████████████████████████████| 2500/2500 [08:36<00:00,  4.84it/s, loss=3.31]\n",
      "Training epoch [3/3]: 100%|███████████████████████████████████████████████████████| 2500/2500 [08:32<00:00,  4.87it/s, loss=3.48]\n"
     ]
    }
   ],
   "source": [
    "for ep in range(epochs):\n",
    "    pbar = tqdm(LCSTS_train)\n",
    "    pbar.set_description(f\"Training epoch [{ep+1}/{epochs}]\")\n",
    "    for inputs, targets in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        loss = t5_model(input_ids=inputs, labels=targets).loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_postfix(loss = loss.item())\n",
    "    # torch.save(t5_model, f'./saved_models/ep{ep}.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify(s):\n",
    "    return s.replace('[CLS]','').replace('[PAD]','').replace('[SEP]','').replace('[UNK]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   文 本 摘 要 ： 日 前 ， 方 舟 子 发 文 直 指 林 志 颖 旗 下 爱 碧 丽 推 销 假 保 健 品 ， 引 起 哗 然 。 调 查 发 现 ， 爱 碧 丽 没 有 自 己 的 生 产 加 工 厂 。 其 胶 原 蛋 白 饮 品 无 核 心 研 发 ， 全 部 代 工 生 产 。 号 称 有  逆 生 长  功 效 的 爱 碧 丽  梦 幻 奇 迹 限 量 组  售 价 高 达 1080 元 ， 实 际 成 本 仅 为 每 瓶 4 元 ！      \n",
      "output:    方 舟 子 发 文 直 指 林 志 颖 旗 下 爱 碧                                                \n",
      "answer:   林 志 颖 公 司 疑 涉 虚 假 营 销 无 厂 房 无 研 发      \n",
      "\n",
      "input:   文 本 摘 要 ： 韩 方 应 对 路 径 可 以 概 括 为 ： 企 业 道 歉 担 责 ； 政 府 公 正 不 护 短 ； 民 间 祈 福 关 怀 。 他 们 深 知 形 象 的 重 要 ， 竭 力 呵 护 企 业 品 牌 和 国 家 形 象 。 正 如 有 评 论 ， 韩 国  政 府 + 企 业 + 民 众  三 位 一 体 式 呵 护 韩 国 国 家 形 象 的  苦 心 经 营  ， 的 确 有 值 得 我 们 借 鉴 之 处 。       \n",
      "output:    韩 国  政 府 + 企 业 + 民 众  三 位 一 体 式 呵 护 韩 国 家 形 象                                      \n",
      "answer:   从 韩 亚 航 空 事 故 看 其 应 对 路 径          \n",
      "\n",
      "input:   文 本 摘 要 ： 63 岁 退 休 教 师 谢 淑 华 ， 拉 着 人 力 板 车 ， 历 时 1 年 ， 走 了 2 万 4 千 里 路 ， 带 着 年 过 九 旬 的 妈 妈 环 游 中 国 ， 完 成 了 妈 妈  一 辈 子 在 锅 台 边 转 ， 也 想 出 去 走 走  的 心 愿 。 她 说 ：  妈 妈 愿 意 出 去 走 走 ， 我 就 愿 意 拉 着 ， 孝 心 不 能 等 ， 能 走 多 远 就 走 多 远 。          \n",
      "output:     妈 妈 愿 意 走 走                                                       \n",
      "answer:   女 子 用 板 车 拉 九 旬 老 母 环 游 中 国 1 年 走 2 万 4 千 里 \n",
      "\n",
      "input:   文 本 摘 要 ： 昨 天 ， 包 括 工 农 中 建 交 五 大 行 在 内 的 多 家 银 行 ， 不 约 而 同 地 在 官 网 发 布 公 告 称 ， 它 们 的 房 地 产 贷 款 政 策 没 有 变 化 。 多 家 银 行 表 示 ， 会 支 持 居 民 购 买 首 套 住 房 。 一 名 金 融 问 题 专 家 称 ，  目 前 房 价 不 具 备 大 涨 大 跌 的 基 础 ， 特 别 是 一 二 线 城 市 狂 跌 的 可 能 性 小 。     \n",
      "output:    多 家 银 行 ：  目 前 房 价 不 具 备 大 涨 大 跌                                             \n",
      "answer:   银 行 集 体 发 声 ： 房 贷 政 策 没 变          \n",
      "\n",
      "input:   文 本 摘 要 ： 广 东 4 名 律 师 致 函 中 国 民 航 局 ， 要 求 其 规 定 ， 航 班 起 飞 前 要 向 乘 客 公 布 机 组 人 员 信 息 包 括 安 全 飞 行 时 间 、 职 业 经 历 等 。 沪 上 业 内 人 士 认 为 ， 一 般 能 被 安 排 执 飞 任 务 的 飞 行 员 ， 均 拥 有 民 航 认 可 的 飞 行 资 质 。 而 责 任 心 和 使 命 感 是 无 法 通 过 飞 行 时 间 反 映 。       \n",
      "output:                                                                 \n",
      "answer:   四 律 师 上 书 民 航 总 局 ： 起 飞 前 应 公 布 机 长 信 息   \n",
      "\n",
      "input:   文 本 摘 要 ： 任 教 五 十 年 ， 钱 理 群 在 2012 年 教 师 节 前 夕 宣 布  告 别 教 育  。 从 北 大 退 休 后 ， 钱 理 群 投 身 中 学 教 育 ， 试 图  改 变 人 心  ， 他 以 鲁 迅 自 励 ， 要 在 绝 望 中 反 抗 ， 但 基 础 教 育 十 年 试 水 ， 却 令 他 收 获  丰 富 的 痛 苦  。 他 说 ，  切 不 能 为 应 试 教 育 服 务 的 教 育 根 本 无 立 足 之 地 。 \n",
      "output:    钱 理 群 投 身 中 学 教 育                                                     \n",
      "answer:   钱 理 群  告 别 教 育               \n",
      "\n",
      "input:   文 本 摘 要 ： ① 北 京 和 上 海 户 籍 的 游 客 可 获 得 韩 国 多 次 签 证 ； ②  整 容 客  可 以 不 经 由 韩 国 使 领 馆 、 直 接 在 网 上 申 请 签 证 ； ③ 中 泰 免 签 的 实 施 日 期 尚 未 敲 定 ； ④ 越 南 已 向 中 国 持 通 行 证 旅 游 的 公 民 全 面 开 放 。                                \n",
      "output:    上 海 户 籍 游 客 可 获 得 韩 国 多 次 签 证                                               \n",
      "answer:   中 国 游 客 大 增 多 国 放 宽 签 证           \n",
      "\n",
      "input:   文 本 摘 要 ： 12 月 12 日 ， 多 家 被 立 案 稽 查 的 沪 市 公 司 集 体 对 外 发 布 退 市 风 险 提 示 公 告 ， *  国 创 位 列 \" \" 黑 名 单 \" \" 。 目 前 证 监 会 调 查 仍 在 进 行 ， *  国 创 尚 未 收 到 此 次 立 案 调 查 书 面 结 论 意 见 。 一 旦 立 案 调 查 事 项 触 及 相 关 规 定 ， 公 司 股 票 将 被 实 施 退 市 风 险 警 示 。 \"      \n",
      "output:     国 创 位 列 \" \" 黑 名 单 \" \" 黑 名 单 \" \"                                             \n",
      "answer:   信 披 违 规 外 加 业 绩 亏 损 *  国 创 退 市 风 险 概 率 大 增 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs, summary = next(iter(LCSTS_validation))\n",
    "x = [tokenizer.batch_decode(inputs)]\n",
    "y = [tokenizer.batch_decode(summary)]\n",
    "pred_y = [tokenizer.batch_decode(t5_model.generate(inputs, max_length=output_max_length))]\n",
    "    \n",
    "for i in range(len(x)):\n",
    "    for j in range(len(x[0])):\n",
    "        print(\"input: \", simplify(x[i][j]))\n",
    "        print(\"output: \", simplify(pred_y[i][j]))\n",
    "        print(\"answer: \", simplify(y[i][j]))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████████████| 1086/1086 [24:10<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 score on epoch 2: {'Rouge-L-P': 0.0, 'Rouge-L-R': 0.0, 'Rouge-L-F': 0.0, 'Rouge-2-P': 0.0, 'Rouge-2-R': 0.0, 'Rouge-2-F': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Rouge-2 score on epoch {ep}:\", evaluate(t5_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGZgD2IBxgn4"
   },
   "source": [
    "## GPT2 訓練 & 測試\n",
    " - 將資料成批次輸入模型，並獲取其損失函數數值，隨後計算梯度優化\n",
    " - tqdm用來顯示模型的訓練進度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GPT2_tensor(sample):\n",
    "    encoded_x = tokenizer.batch_encode_plus([each[0] for each in sample], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    encoded_y = tokenizer.batch_encode_plus([each[1] for each in sample], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    return encoded_x[\"input_ids\"].to(device), encoded_x[\"attention_mask\"].to(device), encoded_y[\"input_ids\"].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCSTS_GPT2_train = DataLoader(LCSTSDataset(split=\"train[:20000]\"),\n",
    "                              collate_fn=get_GPT2_tensor,\n",
    "                              batch_size=train_batch_size,\n",
    "                              shuffle=True)\n",
    "\n",
    "LCSTS_GPT2_validation = DataLoader(LCSTSDataset(split=\"validation[:10000]\"),\n",
    "                                   collate_fn=get_GPT2_tensor,\n",
    "                                   batch_size=validation_batch_size,\n",
    "                                   shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT2_model = T.GPT2LMHeadModel.from_pretrained(\"openai-community/gpt2\", cache_dir=\"./cache/\").to(device)\n",
    "tokenizer = T.BertTokenizer.from_pretrained(\"google-bert/bert-base-chinese\", cache_dir=\"./cache/\")\n",
    "optimizer = AdamW(GPT2_model.parameters(), lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(21128, 768)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT2_model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "MjPwHOCmxgn4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch [1/3]: 100%|███████████████████████████████████████████████████████| 2500/2500 [05:52<00:00,  7.10it/s, loss=6.53]\n",
      "Training epoch [2/3]: 100%|███████████████████████████████████████████████████████| 2500/2500 [05:52<00:00,  7.10it/s, loss=5.49]\n",
      "Training epoch [3/3]: 100%|███████████████████████████████████████████████████████| 2500/2500 [05:51<00:00,  7.12it/s, loss=5.77]\n"
     ]
    }
   ],
   "source": [
    "GPT2_model = GPT2_model.to(device)\n",
    "GPT2_model.train()\n",
    "\n",
    "for ep in range(epochs):\n",
    "    pbar = tqdm(LCSTS_GPT2_train)\n",
    "    pbar.set_description(f\"Training epoch [{ep+1}/{epochs}]\")\n",
    "    for input_ids, attention_mask, summary in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = GPT2_model(input_ids=input_ids, labels=input_ids, attention_mask=attention_mask)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_postfix(loss = loss.item())\n",
    "    # torch.save(t5_model, f'./saved_models/ep{ep}.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   文 本 摘 要 ： 日 前 ， 方 舟 子 发 文 直 指 林 志 颖 旗 下 爱 碧 丽 推 销 假 保 健 品 ， 引 起 哗 然 。 调 查 发 现 ， 爱 碧 丽 没 有 自 己 的 生 产 加 工 厂 。 其 胶 原 蛋 白 饮 品 无 核 心 研 发 ， 全 部 代 工 生 产 。 号 称 有  逆 生 长  功 效 的 爱 碧 丽  梦 幻 奇 迹 限 量 组  售 价 高 达 1080 元 ， 实 际 成 本 仅 为 每 瓶 4 元 ！      \n",
      "output:   文 本 摘 要 ： 日 前 ， 方 舟 子 发 文 直 指 林 志 颖 旗 下 爱 碧 丽 推 销 假 保 健 品 ， 引 起 哗 然 。 调 查 发 现 ， 爱 碧 丽 没 有 自 己 的 生 产 加 工 厂 。 其 胶 原 蛋 白 饮 品 无 核 心 研 发 ， 全 部 代 工 生 产 。 号 称 有  逆 生 长  功 效 的 爱 碧 丽  梦 幻 奇 迹 限 量 组  售 价 高 达 1080 元 ， 实 际 成 本 仅 为 每 瓶 4 元 ！                                                                                    \n",
      "answer:   林 志 颖 公 司 疑 涉 虚 假 营 销 无 厂 房 无 研 发      \n",
      "\n",
      "input:   文 本 摘 要 ： 韩 方 应 对 路 径 可 以 概 括 为 ： 企 业 道 歉 担 责 ； 政 府 公 正 不 护 短 ； 民 间 祈 福 关 怀 。 他 们 深 知 形 象 的 重 要 ， 竭 力 呵 护 企 业 品 牌 和 国 家 形 象 。 正 如 有 评 论 ， 韩 国  政 府 + 企 业 + 民 众  三 位 一 体 式 呵 护 韩 国 国 家 形 象 的  苦 心 经 营  ， 的 确 有 值 得 我 们 借 鉴 之 处 。       \n",
      "output:   文 本 摘 要 ： 韩 方 应 对 路 径 可 以 概 括 为 ： 企 业 道 歉 担 责 ； 政 府 公 正 不 护 短 ； 民 间 祈 福 关 怀 。 他 们 深 知 形 象 的 重 要 ， 竭 力 呵 护 企 业 品 牌 和 国 家 形 象 。 正 如 有 评 论 ， 韩 国  政 府 + 企 业 + 民 众  三 位 一 体 式 呵 护 韩 国 国 家 形 象 的  苦 心 经 营  ， 的 确 有 值 得 我 们 借 鉴 之 处 。                                                                                     \n",
      "answer:   从 韩 亚 航 空 事 故 看 其 应 对 路 径          \n",
      "\n",
      "input:   文 本 摘 要 ： 63 岁 退 休 教 师 谢 淑 华 ， 拉 着 人 力 板 车 ， 历 时 1 年 ， 走 了 2 万 4 千 里 路 ， 带 着 年 过 九 旬 的 妈 妈 环 游 中 国 ， 完 成 了 妈 妈  一 辈 子 在 锅 台 边 转 ， 也 想 出 去 走 走  的 心 愿 。 她 说 ：  妈 妈 愿 意 出 去 走 走 ， 我 就 愿 意 拉 着 ， 孝 心 不 能 等 ， 能 走 多 远 就 走 多 远 。          \n",
      "output:   文 本 摘 要 ： 63 岁 退 休 教 师 谢 淑 华 ， 拉 着 人 力 板 车 ， 历 时 1 年 ， 走 了 2 万 4 千 里 路 ， 带 着 年 过 九 旬 的 妈 妈 环 游 中 国 ， 完 成 了 妈 妈  一 辈 子 在 锅 台 边 转 ， 也 想 出 去 走 走  的 心 愿 。 她 说 ：  妈 妈 愿 意 出 去 走 走 ， 我 就 愿 意 拉 着 ， 孝 心 不 能 等 ， 能 走 多 远 就 走 多 远 。                                                                                        \n",
      "answer:   女 子 用 板 车 拉 九 旬 老 母 环 游 中 国 1 年 走 2 万 4 千 里 \n",
      "\n",
      "input:   文 本 摘 要 ： 昨 天 ， 包 括 工 农 中 建 交 五 大 行 在 内 的 多 家 银 行 ， 不 约 而 同 地 在 官 网 发 布 公 告 称 ， 它 们 的 房 地 产 贷 款 政 策 没 有 变 化 。 多 家 银 行 表 示 ， 会 支 持 居 民 购 买 首 套 住 房 。 一 名 金 融 问 题 专 家 称 ，  目 前 房 价 不 具 备 大 涨 大 跌 的 基 础 ， 特 别 是 一 二 线 城 市 狂 跌 的 可 能 性 小 。     \n",
      "output:   文 本 摘 要 ： 昨 天 ， 包 括 工 农 中 建 交 五 大 行 在 内 的 多 家 银 行 ， 不 约 而 同 地 在 官 网 发 布 公 告 称 ， 它 们 的 房 地 产 贷 款 政 策 没 有 变 化 。 多 家 银 行 表 示 ， 会 支 持 居 民 购 买 首 套 住 房 。 一 名 金 融 问 题 专 家 称 ，  目 前 房 价 不 具 备 大 涨 大 跌 的 基 础 ， 特 别 是 一 二 线 城 市 狂 跌 的 可 能 性 小 。                                                                                   \n",
      "answer:   银 行 集 体 发 声 ： 房 贷 政 策 没 变          \n",
      "\n",
      "input:   文 本 摘 要 ： 广 东 4 名 律 师 致 函 中 国 民 航 局 ， 要 求 其 规 定 ， 航 班 起 飞 前 要 向 乘 客 公 布 机 组 人 员 信 息 包 括 安 全 飞 行 时 间 、 职 业 经 历 等 。 沪 上 业 内 人 士 认 为 ， 一 般 能 被 安 排 执 飞 任 务 的 飞 行 员 ， 均 拥 有 民 航 认 可 的 飞 行 资 质 。 而 责 任 心 和 使 命 感 是 无 法 通 过 飞 行 时 间 反 映 。       \n",
      "output:   文 本 摘 要 ： 广 东 4 名 律 师 致 函 中 国 民 航 局 ， 要 求 其 规 定 ， 航 班 起 飞 前 要 向 乘 客 公 布 机 组 人 员 信 息 包 括 安 全 飞 行 时 间 、 职 业 经 历 等 。 沪 上 业 内 人 士 认 为 ， 一 般 能 被 安 排 执 飞 任 务 的 飞 行 员 ， 均 拥 有 民 航 认 可 的 飞 行 资 质 。 而 责 任 心 和 使 命 感 是 无 法 通 过 飞 行 时 间 反 映 。                                                                                     \n",
      "answer:   四 律 师 上 书 民 航 总 局 ： 起 飞 前 应 公 布 机 长 信 息   \n",
      "\n",
      "input:   文 本 摘 要 ： 任 教 五 十 年 ， 钱 理 群 在 2012 年 教 师 节 前 夕 宣 布  告 别 教 育  。 从 北 大 退 休 后 ， 钱 理 群 投 身 中 学 教 育 ， 试 图  改 变 人 心  ， 他 以 鲁 迅 自 励 ， 要 在 绝 望 中 反 抗 ， 但 基 础 教 育 十 年 试 水 ， 却 令 他 收 获  丰 富 的 痛 苦  。 他 说 ，  切 不 能 为 应 试 教 育 服 务 的 教 育 根 本 无 立 足 之 地 。 \n",
      "output:   文 本 摘 要 ： 任 教 五 十 年 ， 钱 理 群 在 2012 年 教 师 节 前 夕 宣 布  告 别 教 育  。 从 北 大 退 休 后 ， 钱 理 群 投 身 中 学 教 育 ， 试 图  改 变 人 心  ， 他 以 鲁 迅 自 励 ， 要 在 绝 望 中 反 抗 ， 但 基 础 教 育 十 年 试 水 ， 却 令 他 收 获  丰 富 的 痛 苦  。 他 说 ，  切 不 能 为 应 试 教 育 服 务 的 教 育 根 本 无 立 足 之 地 。                                              。                                 \n",
      "answer:   钱 理 群  告 别 教 育               \n",
      "\n",
      "input:   文 本 摘 要 ： ① 北 京 和 上 海 户 籍 的 游 客 可 获 得 韩 国 多 次 签 证 ； ②  整 容 客  可 以 不 经 由 韩 国 使 领 馆 、 直 接 在 网 上 申 请 签 证 ； ③ 中 泰 免 签 的 实 施 日 期 尚 未 敲 定 ； ④ 越 南 已 向 中 国 持 通 行 证 旅 游 的 公 民 全 面 开 放 。                                \n",
      "output:   文 本 摘 要 ： ① 北 京 和 上 海 户 籍 的 游 客 可 获 得 韩 国 多 次 签 证 ； ②  整 容 客  可 以 不 经 由 韩 国 使 领 馆 、 直 接 在 网 上 申 请 签 证 ； ③ 中 泰 免 签 的 实 施 日 期 尚 未 敲 定 ； ④ 越 南 已 向 中 国 持 通 行 证 旅 游 的 公 民 全 面 开 放 。                                                                                                              \n",
      "answer:   中 国 游 客 大 增 多 国 放 宽 签 证           \n",
      "\n",
      "input:   文 本 摘 要 ： 12 月 12 日 ， 多 家 被 立 案 稽 查 的 沪 市 公 司 集 体 对 外 发 布 退 市 风 险 提 示 公 告 ， *  国 创 位 列 \" \" 黑 名 单 \" \" 。 目 前 证 监 会 调 查 仍 在 进 行 ， *  国 创 尚 未 收 到 此 次 立 案 调 查 书 面 结 论 意 见 。 一 旦 立 案 调 查 事 项 触 及 相 关 规 定 ， 公 司 股 票 将 被 实 施 退 市 风 险 警 示 。 \"      \n",
      "output:   文 本 摘 要 ： 12 月 12 日 ， 多 家 被 立 案 稽 查 的 沪 市 公 司 集 体 对 外 发 布 退 市 风 险 提 示 公 告 ， *  国 创 位 列 \" \" 黑 名 单 \" \" 。 目 前 证 监 会 调 查 仍 在 进 行 ， *  国 创 尚 未 收 到 此 次 立 案 调 查 书 面 结 论 意 见 。 一 旦 立 案 调 查 事 项 触 及 相 关 规 定 ， 公 司 股 票 将 被 实 施 退 市 风 险 警 示 。 \"                                                                                    \n",
      "answer:   信 披 违 规 外 加 业 绩 亏 损 *  国 创 退 市 风 险 概 率 大 增 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs, attention_mask, summary = next(iter(LCSTS_GPT2_validation))\n",
    "x = [tokenizer.batch_decode(inputs)]\n",
    "y = [tokenizer.batch_decode(summary)]\n",
    "pred_y = [tokenizer.batch_decode(GPT2_model.generate(inputs,\n",
    "                                                        max_length=output_max_length, \n",
    "                                                        attention_mask=attention_mask,\n",
    "                                                        pad_token_id=50256)# hugging face produce error if pad_token_id is not set\n",
    "                                        )]\n",
    "    \n",
    "for i in range(len(x)):\n",
    "    for j in range(len(x[0])):\n",
    "        print(\"input: \", simplify(x[i][j]))\n",
    "        print(\"output: \", simplify(pred_y[i][j]))\n",
    "        print(\"answer: \", simplify(y[i][j]))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    pbar = tqdm(LCSTS_GPT2_validation)\n",
    "    pbar.set_description(f\"Evaluating\")\n",
    "\n",
    "    for inputs, attention_mask, summary in pbar:\n",
    "        # model output\n",
    "        output = [tokenizer.batch_decode(model.generate(inputs,\n",
    "                                                        max_length=output_max_length, \n",
    "                                                        attention_mask=attention_mask,\n",
    "                                                        pad_token_id=50256)# hugging face produce error if pad_token_id is not set\n",
    "                                        )]\n",
    "        # 正確答案\n",
    "        summary = [tokenizer.batch_decode(summary)]\n",
    "        for i in range(len(output)):\n",
    "            for s in output:\n",
    "                rouge.update(([s], [summary]))\n",
    "    return rouge.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████████████| 1086/1086 [20:29<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-2 score on epoch 2: {'Rouge-L-P': 0.0, 'Rouge-L-R': 0.0, 'Rouge-L-F': 0.0, 'Rouge-2-P': 0.0, 'Rouge-2-R': 0.0, 'Rouge-2-F': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Rouge-2 score on epoch {ep}:\", evaluate(GPT2_model))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
